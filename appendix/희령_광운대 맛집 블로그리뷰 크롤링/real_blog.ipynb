{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d9b5cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "from tqdm.notebook import tqdm # 상태진행바\n",
    "import pandas as pd\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import json\n",
    "\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "#excel control library, ! pip install openpyxl\n",
    "from openpyxl import Workbook\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc105d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = ['https://m.place.naver.com/restaurant/166240712/home', 'https://m.place.naver.com/restaurant/1083519696/home']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da41099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_list(url):\n",
    "    blog_list = []\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')  # 크롬 창이 뜨지 않도록 설정\n",
    "    browser = webdriver.Chrome(service=service)\n",
    "    browser.get(url)\n",
    "    desired_text = \"리뷰\"\n",
    "    try:\n",
    "        menu_list = WebDriverWait(browser, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.tpj9w._tab-menu')))\n",
    "\n",
    "        for menu in menu_list:\n",
    "            if menu.text == desired_text:\n",
    "                menu.click()  # 원하는 텍스트가 있는 메뉴를 클릭\n",
    "                break\n",
    "\n",
    "        review_list = WebDriverWait(browser, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.YsfhA')))\n",
    "        if len(review_list) > 1:\n",
    "            review_list[1].click()  # Click on the review tab\n",
    "            \n",
    "        while True:\n",
    "            try:\n",
    "                more_button = WebDriverWait(browser, 3).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, 'a.fvwqf')))\n",
    "                more_button.click()\n",
    "                time.sleep(0.4)  # Moderate delay to simulate user behavior\n",
    "            except:\n",
    "                break\n",
    "        \n",
    "        html = browser.page_source\n",
    "        bs = BeautifulSoup(html, 'lxml')\n",
    "        blogs = bs.select(\"li.xg2_q\")\n",
    "\n",
    "        for i in blogs:\n",
    "            a_tag = i.find('a', href=True)\n",
    "            if a_tag:\n",
    "                blog_list.append(a_tag['href'])\n",
    "    except:\n",
    "        print(\"get_url_list_error: \" + url)\n",
    "        return False\n",
    "    else:\n",
    "        return blog_list\n",
    "    finally:\n",
    "        browser.quit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c52e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blog_reviews(url_list):\n",
    "    for idx, url in enumerate(url_list):\n",
    "        blog_url_list = get_url_list(url)\n",
    "        df_text = pd.DataFrame(columns=['date', 'url', 'title', 'text']) \n",
    "        df_idx = 0\n",
    "        if blog_url_list:\n",
    "            for url in blog_url_list:\n",
    "                res = requests.get(url)\n",
    "                res.raise_for_status()\n",
    "                soup = BeautifulSoup(res.text, \"lxml\")\n",
    "                try:\n",
    "                    date = soup.find(\"p\", attrs={'class':'blog_date'}).text.rstrip()\n",
    "                    title = soup.find(\"span\", attrs={'class':'se-fs- se-ff-'}).text\n",
    "                    content = soup.find(\"div\", attrs={'class':'se-main-container'}).text\n",
    "                    content = content.replace('\\n', '')\n",
    "                    #content = content.replace('\\u200b', '')\n",
    "\n",
    "                    df_text.loc[df_idx] = [date, url, title, content]\n",
    "                    df_idx += 1\n",
    "                    time.sleep(0.5)\n",
    "                except Exception as e:\n",
    "#                     print(f\"blog error: URL: {url}, Error: {str(e)}\")\n",
    "                    continue\n",
    "            csv_name = 'data/'+ str(idx) + '.csv'\n",
    "            df_text.to_csv(csv_name, index=False, encoding='utf-8-sig')\n",
    "            print(\"clear: \" + str(idx))\n",
    "        else:\n",
    "            print(\"no blog_url_list\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82dd703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('store.csv')\n",
    "desired_columns = df['링크']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fe892ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열에 'https://'를 추가합니다.\n",
    "url_list = ['https://' + url for url in desired_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43a7c002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear: 0\n",
      "clear: 1\n",
      "clear: 2\n",
      "clear: 3\n",
      "clear: 4\n",
      "clear: 5\n",
      "clear: 6\n",
      "clear: 7\n",
      "get_url_list_error: https://m.place.naver.com/restaurant/1585175133/home\n",
      "no blog_url_list\n",
      "clear: 9\n",
      "clear: 10\n",
      "clear: 11\n",
      "clear: 12\n",
      "clear: 13\n",
      "clear: 14\n",
      "clear: 15\n",
      "clear: 16\n",
      "clear: 17\n",
      "clear: 18\n",
      "clear: 19\n",
      "clear: 20\n",
      "clear: 21\n",
      "clear: 22\n",
      "clear: 23\n",
      "clear: 24\n",
      "clear: 25\n",
      "clear: 26\n",
      "clear: 27\n",
      "clear: 28\n",
      "clear: 29\n",
      "clear: 30\n",
      "clear: 31\n",
      "clear: 32\n",
      "clear: 33\n",
      "clear: 34\n",
      "clear: 35\n",
      "clear: 36\n",
      "clear: 37\n",
      "clear: 38\n",
      "clear: 39\n",
      "clear: 40\n",
      "clear: 41\n",
      "clear: 42\n",
      "clear: 43\n",
      "clear: 44\n",
      "clear: 45\n",
      "clear: 46\n",
      "get_url_list_error: https://m.place.naver.com/restaurant/1019293954/home\n",
      "no blog_url_list\n",
      "get_url_list_error: https://m.place.naver.com/restaurant/1880578521/home\n",
      "no blog_url_list\n",
      "clear: 49\n",
      "clear: 50\n",
      "clear: 51\n",
      "get_url_list_error: https://m.place.naver.com/restaurant/1009817270/home\n",
      "no blog_url_list\n",
      "clear: 53\n",
      "clear: 54\n",
      "get_url_list_error: https://m.place.naver.com/restaurant/1439850593/home\n",
      "no blog_url_list\n",
      "clear: 56\n",
      "clear: 57\n",
      "clear: 58\n",
      "get_url_list_error: https://m.place.naver.com/restaurant/1590075546/home\n",
      "no blog_url_list\n",
      "clear: 60\n",
      "clear: 61\n",
      "clear: 62\n",
      "clear: 63\n",
      "clear: 64\n",
      "clear: 65\n",
      "get_url_list_error: https://m.place.naver.com/restaurant/1771727068/home\n",
      "no blog_url_list\n",
      "clear: 67\n",
      "clear: 68\n",
      "get_url_list_error: https://m.place.naver.com/restaurant/1046232249/home\n",
      "no blog_url_list\n",
      "clear: 70\n",
      "get_url_list_error: https://m.place.naver.com/restaurant/1044069286/home\n",
      "no blog_url_list\n",
      "clear: 72\n",
      "clear: 73\n",
      "clear: 74\n"
     ]
    }
   ],
   "source": [
    "get_blog_reviews(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a38af13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
